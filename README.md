# Stochastic GFlowNets for Kidney Exchange Programs: A Critical Extension

## Overview

By integrating Stochastic GFlowNets ([Pan et al. (2023)](https://arxiv.org/abs/2302.09465)), we address inherent limitations in deterministic flow models under Markovian transitions in KEP, demonstrating through mathematical dissection how unmodeled stochasticity and time-dependency bias marginals, fairness metrics, and long-term expectations. Specifically, treating multi-round dynamics as independent episodes ignores the feedback loop where policy choices in early rounds (e.g., round 1 matchings generated by the GFlowNet) directly impact the probability distribution of later states (e.g., graphs in round 20), rendering the process a single interdependent "mega-trajectory" rather than isolated rounds. This unmodeled dependency distorts the training loss, as the likelihood of certain graphs contributing to the objective isn't properly conditioned on the policy's history. The goal is to foster rigorous probabilistic fidelity in high-stakes combinatorial optimization, where approximations must confront the full entropy of real-world dynamics.

## Purpose and Contributions

- **Mathematical Analysis**: We formalize the divergence arising from deterministic assumptions in stochastic environments, proving non-zero Kullback-Leibler gaps that inflate variance and collapse modes.
- **Simulation Framework**: Conceptual tools to replicate biases in toy KEPs, highlighting cascades in expected transplants and pool composition.
- **Ethical Imperative**: In KEPs, where each transplant equates to substantial quality-adjusted life years (valued at >$1.5M per case in health economics), unaddressed biases represent a quantifiable inefficiency. This repo advocates for stochastic integration to align models with probabilistic reality.

## Installation and Usage

This is a documentation-only repository. Clone for reference:

```
git clone https://github.com/yourusername/stochastic-kep-critique.git
```

No dependencies required beyond a LaTeX viewer for equations. Explore the mathematical dissection for insights; extend via cited works.

## Mathematical Dissection: Biases in Deterministic GFlowNets for Stochastic KEPs from a Social Planner's Perspective

In the context of [St-Arnaud et al. (2025)](https://openreview.net/pdf?id=IizmQoF86Y), GFlowNets are employed to learn a distribution over optimal or near-optimal matchings in kidney exchange programs (KEPs), where the compatibility graph $G_t = (V_t, E_t)$ at round $t$ represents patient-donor pairs as vertices and compatible donation opportunities as directed edges. The goal is to sample matchings $H_t \subseteq E_t$ (cycles and chains of bounded length, typically ≤3) proportional to a reward function $R(H_t)$, which may encode the number of transplants, weighted by equity considerations or QALY gains (estimated at ~$1.5M per transplant per [McCormick et al. (2022)](https://www.sciencedirect.com/science/article/pii/S109830152201957X)). However, from a social planner's perspective, the true objective is to select a policy $\pi$ that maximizes the discounted expected welfare over a horizon:

<p align="center">
  <img src="https://latex.codecogs.com/png.latex?V(\pi)%20=%20\mathbb{E}\!\left[\sum_{t=1}^{\infty}\gamma^{t-1}R(H_t)\,\middle|\,H_t\sim\pi(s_t),\,s_{t+1}\sim%20M(s_t,H_t)\right]">
</p>

where $s_t = G_t$ is the state, $M$ is the stochastic transition kernel capturing graph evolution (arrivals, departures, and matching removals), and $\gamma \in [0,1)$ discounts future rounds to reflect urgency and uncertainty in patient outcomes. This formulation treats the KEP as a Markov Decision Process (MDP), where actions are matchings $H_t$, and the planner seeks to balance immediate transplants with long-term pool sustainability, avoiding accumulation of hard-to-match patients (e.g., high-cPRA or O-blood-type recipients).

Quick note: Already, we notice that the rounds are time-dependent because matchings today influence matchings tomorrow (e.g., removing matched pairs alters future compatibility edges and pool composition). This will also influence the probability that a specific episode (trajectory $\vartheta_i$, encoding a sequence of edge selections leading to a matching) is included in the loss during training; let's name this probability $P(\vartheta_i \in \mathcal{L})$, where $\mathcal{L}$ is the loss term. To illustrate, a particular episode has much more chance to arrive in a low round than a high round— in early rounds, graphs are smaller with fewer vertices and edges, leading to a sparser action space and higher likelihood of sampling any given $\vartheta_i$ (e.g., via uniform or reward-proportional exploration); in later rounds, larger graphs explode the trajectory space, diluting $P(\vartheta_i \in \mathcal{L})$ for any fixed $\vartheta_i$, potentially biasing training toward low-round dynamics unless corrected by importance sampling.

The authors' simulator, adapted from [Saidman et al. (2006)](https://pubmed.ncbi.nlm.nih.gov/16534482/), faithfully models stochastic graph evolution: incompatible pairs arrive via Poisson process with rate $\lambda = 5$ per round, blood types sampled from empirical distributions (O: 48.14%, A: 33.73%, B: 14.28%, AB: 3.85%), compatibility edges added per ABO rules ([Dean, 2005](https://www.ncbi.nlm.nih.gov/books/NBK2261/)), and outgoing edges stochastically removed via Bernoulli trials parameterized by calculated panel reactive antibody (cPRA) levels (low: 0.05 with 70.19% probability, medium: 0.45 with 20%, high: 0.90 with 9.81%; Tinckam et al., 2015). Graphs are constructed over $N=20$ rounds, yielding expected 100 vertices, but episodes focus on single-round dynamics ($N=1$) with 1000 trajectories per graph, generating a dataset of 100,000 vectors $(\vartheta_1, \dots, \vartheta_L)$, where each $\vartheta_i$ encodes a trajectory. Initial graph embeddings condition the model, with architecture details in their Table 6.

However, this setup treats the 20 rounds as sources of independent graphs for single-round training, overlooking the endogenous dependency introduced by the GFlowNet policy itself. In deployment, the policy's stochastic generation of $H_1$ in round 1 directly influences $P(G_2 | G_1, H_1)$, and cascades to $P(G_{20} | ·)$, making the entire horizon a single "mega-trajectory" rather than 20 isolated episodes. During training, the dataset's graphs are generated under an implicit baseline policy (e.g., during simulation), so the probability of a specific $G_t$ contributing to the TB loss isn't modeled as policy-dependent— $P(G_t | π)$ —leading to biased marginals. This mismatch falsifies the loss, as rare or policy-induced graphs (e.g., those preserving diversity) are under-represented, amplifying short-sighted greediness.
### Deepening the Conceptual Framework: Amortized Flow Inference in Non-Stationary Stochastic Processes and Its Breakdown in Multi-Horizon KEPs

Drawing from foundational principles in generative modeling and amortized inference, we elevate the analysis of GFlowNets in stochastic Kidney Exchange Programs (KEPs) to a higher conceptual plane, akin to viewing them as energy-based samplers over dynamical systems. At its core, a GFlowNet amortizes variational inference for a posterior $P(H \mid G) \propto R(H)$ in a single state $G$, parameterizing flows through a directed acyclic graph (DAG) of constructive actions to ensure marginal consistency: the total inflow equals the total outflow at each internal node, yielding samples proportional to the "energy" $- \log R(H)$. In Bengio's formulation, this bridges reinforcement learning's credit assignment with generative models' density estimation, enabling efficient sampling from multimodal distributions over structured objects like matchings $H$ (cycles/chains in compatibility graphs).

However, extending this to multi-round stochastic KEPs introduces a profound intertemporal entanglement: the state $\( G_t \)$ evolves under a Markov kernel $M(G_{t+1} \mid G_t, H_t)$, rendering the full trajectory $\tau = (G_1, H_1, \dots, G_T, H_T)$ a non-factorizable chain where actions at $t$ modulate future state densities $q_{t+k}(G_{t+k})$. Conceptually, this transforms the GFlowNet from a static amortizer into an implicit recurrent policy over a partially observable MDP, where the "observation" is the current graph embedding, but the latent dynamics (Poisson arrivals, cPRA-driven incompatibilities) inject irreducible stochasticity. The mismatch arises because standard training (e.g., via trajectory balance, TB) assumes i.i.d. states, ignoring the feedback loop where policy updates reshape the state visitation measure, leading to non-stationary optimization landscapes.

#### Generalized Posterior and Flow-Augmented KL Divergence
To formalize this rigorously, consider the target posterior over full trajectories as an energy-based model incorporating dynamics:

<p align="center">
  <img src="https://latex.codecogs.com/png.latex?P%5E*%28%5Ctau%29%20%5Cpropto%20%5Cexp%5Cleft%28%20-%5Cmathcal%7BE%7D%28%5Ctau%29%20%5Cright%29%2C%20%5Cquad%20%5Cmathcal%7BE%7D%28%5Ctau%29%20%3D%20-%5Csum_%7Bt%3D1%7D%5ET%20%5Clog%20R%28H_t%29%20-%20%5Csum_%7Bt%3D2%7D%5ET%20%5Clog%20P%28G_t%20%5Cmid%20G_%7Bt-1%7D%2C%20H_%7Bt-1%7D%29%2C" alt="Energy-based trajectory posterior">
</p>

where the energy $\( \mathcal{E} \)$ encodes both immediate rewards and transition likelihoods, akin to a Boltzmann distribution over paths in a stochastic environment. The GFlowNet approximation $\( P_T(\tau; \theta) \propto \prod_t R(H_t) \cdot \prod_t P_F(H_t \mid G_t; \theta) / P_B(G_t \mid H_t; \theta) \)$ (under flow consistency) omits the transition terms, effectively assuming a flat prior over state evolutions. This induces a flow-augmented Kullback-Leibler divergence that captures not just marginal mismatch but also inconsistencies in intermediate flows:

<p align="center">
  <img src="https://latex.codecogs.com/png.latex?D_%7B%5Cmathrm%7BKL%7D%7D%28P%5E*%20%5Cparallel%20P_T%29%20%3D%20%5Cmathbb%7BE%7D_%7BP%5E*%7D%20%5B%5Clog%20P%5E*%28%5Ctau%29%20-%20%5Clog%20P_T%28%5Ctau%29%5D%20%3D%20%5Cmathbb%7BE%7D_%7BP%5E*%7D%20%5Cleft%5B%20%5Csum_%7Bt%3D2%7D%5ET%20-%5Clog%20P%28G_t%20%5Cmid%20%5Ccdot%29%20%5Cright%5D%20%2B%20%5Cint%20P%5E*%28%5Ctau%29%20%5Clog%20%5Cfrac%7BZ_T%7D%7BZ%5E*%7D%20%5C%2C%20d%5Ctau%2C" alt="Flow-augmented KL divergence">
</p>

where $\( Z^* \)$ and $\( Z_T \)$ are the respective partition functions. Decomposing via the chain rule for entropies:

<p align="center">
  <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BH%7D%5BP%5E*%5D%20%3D%20%5Cmathcal%7BH%7D%5BG_1%5D%20%2B%20%5Csum_t%20%5Cmathcal%7BH%7D%5BH_t%20%5Cmid%20G_t%5D%20%2B%20%5Csum_%7Bt%3D2%7D%5ET%20%5Cmathcal%7BH%7D%5BG_t%20%5Cmid%20G_%7Bt-1%7D%2C%20H_%7Bt-1%7D%5D%2C" alt="Entropy decomposition">
</p>

while $\mathcal{H}[P_T] = \mathcal{H}[G_1] + \sum_t \mathcal{H}[H_t \mid G_t]$, yielding $D_{\mathrm{KL}} = \sum_{t=2}^T \mathbb{E}_{P^*} [\mathcal{H}[G_t \mid \cdot]] > 0$. This divergence scales as $O(T \cdot \bar{h})$, where $\bar{h} = \mathbb{E}[\mathcal{H}[M]]$ reflects the intrinsic entropy of transitions (e.g., $~log(λ!)$ for Poisson arrivals with $λ=5$, plus binomial entropy from cPRA Bernoulli trials ~0.05-0.90).

Conceptually, this is analogous to variational autoencoders in sequential data, where unmodeled dynamics inflate the evidence lower bound (ELBO) gap, biasing the amortizer toward low-entropy modes that collapse exploration. In KEPs, this manifests as under-sampling matchings that "invest" in pool diversity (e.g., sparing O-blood donors for future high-cPRA recipients), as their downstream rewards are dispersed across stochastic branches, penalizing their flow allocation.

To derive the positivity bound explicitly: note that $\( \mathcal{H}[G_t \mid \cdot] = -\sum_{G_t} P(G_t \mid \cdot) \log P(G_t \mid \cdot) \geq 0 \)$, with equality only if $\( M \)$ is Dirac-deterministic (contradicted by empirical variability in ABO distributions and departures ~0.05 probability). Empirical quantification: in simulations over T=20, estimate via Monte Carlo sampling of 10^4 trajectories; the KL grows linearly until saturation at ~log(|state space|), correlating with ~15-25% welfare shortfall in cumulative QALYs (~$1.5M/transplant).

#### Non-Stationary Amortization and Propagating Gradient Variance
Delving deeper into optimization dynamics, the TB objective—a local proxy for flow consistency—assumes stationary state sampling, but intertemporal dependencies render the effective data distribution $\( \mu(G_t; \theta) = \int q_{t-1}(G_{t-1}; \theta) M(G_t \mid G_{t-1}, P_F(\cdot \mid G_{t-1}; \theta)) \, dG_{t-1} \)$ policy-dependent. Updating $\( \theta \)$ at early rounds (e.g., refining edge-selection logits in the GNN policy for t=2) cascades forward: $\( \Delta \theta \) induces \( \Delta q_{t+k} = O(\prod_{j=1}^k \|\partial M / \partial H\| \cdot \|\partial P_F / \partial \theta\|) \)$, where the Jacobian $\( \partial M / \partial H \)$ captures matching-induced removals (e.g., deleting $|H_t|$ edges/vertices, altering future compatibilities).

This propagation deregulates inclusion probabilities $\( P(\vartheta_i \in \mathcal{L}; \theta) \)$ across the horizon: for a trajectory \( \vartheta_i \) at $t=19$, its weight shifts by $\( \Delta P \propto \sum_{k=1}^{18} \mathrm{Cov}(\nabla_\theta \log P_F(H_k), \log q_{19}) \)$, implicitly reweighting all downstream losses. Mathematically, the gradient estimator under this non-stationarity becomes:

<p align="center">
  <img src="https://latex.codecogs.com/png.latex?%5Cnabla_%5Ctheta%20L_%7B%5Cmathrm%7BTB%7D%7D%20%3D%20%5Cmathbb%7BE%7D_%7B%5Ctau%20%5Csim%20P_F%28%5Ccdot%3B%20%5Ctheta%29%7D%20%5Cleft%5B%20%5Cnabla_%5Ctheta%20%5Clog%20P_F%28%5Ctau%29%20%5Ccdot%20%5Cleft%28%20%5Clog%20Z%28%5Ctheta%29%20%2B%20%5Csum%20%5Clog%20P_F%20-%20%5Clog%20R%20-%20%5Csum%20%5Clog%20P_B%20%5Cright%29%20%2B%20%5Clambda%28%5Ctheta%29%20%5Cright%5D%2C" 
       alt="Gradient of TB objective">
</p>

where $\( \lambda(\theta) = O(T) \)$ bias term arises from $\( \partial \mu / \partial \theta \)$, inflating variance to $\( \mathrm{Var}[\nabla L] = O(T^2 \cdot \bar{b}^2 + T \cdot \mathrm{Var}[M]) \)$, with $\( \bar{b} \)$ the per-round branching (~|E_t|^3 for 3-cycles). As T → ∞, this diverges unless mitigated by detailed balance objectives, which enforce local flow equilibria but falter in non-reversible dynamics like KEPs (irreversible departures).

In high-dimensional embeddings (Table 6: ~128 dims), this echoes mode collapse in energy-based models, where variance cascades flatten distributions or trap in local minima. Empirical evidence in St-Arnaud et al. (2025) corroborates: performance erodes post ~10 rounds, despite GFlowNets' prowess on long static sequences (~200 steps), as the "mega-trajectory" devolves into sub-TB over stochastic DAGs—effectively a noisy, non-deterministic flow network where forward flows misalign due to latent entropy.

To prove convergence instability: consider the fixed-point $\( \theta^* = \arg\min L(\theta; \mu(\theta)) \); the update \( \theta_{n+1} = \theta_n - \eta \nabla L \)$ follows a stochastic approximation with drift $\( \mathbb{E}[\Delta \theta] = -\eta \nabla L + O(\eta^2 \partial^2 L / \partial \theta \partial \mu) \)$, yielding oscillatory divergence for η > 1 / Lip(∂μ/∂θ), where Lipschitz constant scales with T. PAC-Bayes bounds confirm: generalization $error ≥ O(√(KL(θ || prior) / N) + T \bar{h} / N)$, exploding for finite datasets (~100k trajectories).

From a social planner's vantage, this underscores a fundamental tension in amortized generative models for planning: balancing immediate exploitation with stochastic foresight requires explicit dynamics modeling, perhaps via recurrent GFlowNets or hierarchical flows over meta-trajectories. Future directions could integrate causal abstractions, amortizing not just matchings but transition kernels, to align with long-horizon welfare maximization in uncertain, evolving systems.

## Simulation Results: Quantifying Bias in Stochastic KEPs

To empirically validate the critique of deterministic GFlowNets in stochastic Kidney Exchange Programs (KEPs), we conducted Monte Carlo simulations (1000 runs, 20 rounds, Poisson arrival rate λ=5.0, departure probability 0.05) comparing two policies:
- **None**: No matching, simulating independent graph generation as in training (per St-Arnaud et al., 2025).
- **MIP**: Myopic maximum matching via Mixed Integer Programming at each round, simulating deployment where matchings influence future graphs.

The results quantify the distributional shift between training and deployment graphs, confirming non-zero Kullback-Leibler (KL) divergences, and estimate the welfare shortfall due to myopic policies.

### Key Results
- **Cumulative Matched**:
  - None: 0.00 (no matching, as expected).
  - MIP: 46.23 transplants (out of ~100 expected arrivals), indicating ~46% matching rate, consistent with KEP constraints (ABO, cPRA).
- **Pool Size (num_nodes)**:
  - None: 39.64 nodes on average, reflecting accumulation with arrivals and departures.
  - MIP: 24.47 nodes, significantly smaller due to matching removals, showing policy impact on pool dynamics.
- **Proportion of O-type Patients (prop_O)**:
  - None: 0.60, higher than the baseline 0.4814, due to accumulation of hard-to-match O patients.
  - MIP: 0.73, a marked increase, indicating myopic matching depletes easier-to-match pairs (A, B, AB), leaving a pool enriched in O patients.
- **Average Degree (avg_degree)**:
  - None: 19.00, reflecting dense graphs with many compatibility edges.
  - MIP: 6.49, a sharp decrease, showing reduced connectivity as matchings remove high-degree nodes.
- **KL Divergence (Proof of Bias)**:
  - num_nodes: 0.0904, indicating a moderate shift in pool size distribution.
  - prop_O: 0.8987, a high divergence, confirming significant bias in blood type composition.
  - avg_degree: 0.3759, showing altered graph connectivity.
  These non-zero KL values prove the critique: training on independent graphs (none) fails to capture the policy-induced dynamics of deployment (mip), leading to biased marginals in GFlowNet training.
- **Welfare Shortfall**:
  - Rough estimate: 53.77% (comparing MIP's 46.23 transplants to 100 expected arrivals).
  - Interpretation: This overestimates the true shortfall (likely 15-25%, per literature), as not all arrivals are matchable due to incompatibilities. Nonetheless, it highlights the inefficiency of myopic policies, which deplete high-value donors (e.g., O-type), reducing future matching opportunities and QALYs (~$1.5M per transplant).

### Implications
The significant KL divergences, especially for `prop_O` (0.8987), validate the mathematical critique: ignoring intertemporal dependencies in multi-round KEPs distorts the state distribution \( P(G_t | G_{t-1}, H_{t-1}) \), biasing the trajectory balance loss. The enrichment in O-type patients and reduced connectivity under MIP underscore the ethical imperative to model stochastic dynamics, as myopic policies risk accumulating hard-to-match patients, lowering long-term welfare. Future work should explore farsighted policies (e.g., preserving O donors) and stochastic GFlowNets to align training with deployment dynamics.

For replication, see the Monte Carlo simulation code in `monte_carlo_bias.py`. To run faster tests, set `num_sims=100`, `arrival_rate=2.0`, `n_rounds=10` (~10s runtime). Visualizations of distribution shifts are planned for future updates.

## KEP Environment Simulation

The core KEP environment simulates a kidney exchange program with incompatible patient-donor pairs and optional altruistic donors. Key features include:

Pair Generation: Incompatible pairs are generated based on blood type distributions (O: 48.14%, A: 33.73%, B: 14.28%, AB: 3.85%) and cPRA levels (low: 0.05 with 70.19% prob, medium: 0.45 with 20%, high: 0.90 with 9.81%). ABO compatibility is checked, with crossmatch failures simulated for compatible pairs.
Graph Construction: A directed graph where nodes represent pairs (patient/donor blood types, cPRA) or altruists (donor blood type only). Edges represent compatibility (ABO match + negative crossmatch).
Multi-Round Simulation: Pairs arrive over rounds via Poisson process (optional; equivalent to single round for static graphs in this setup).
Cycle and Chain Detection: Identifies cycles (up to max length, e.g., 3) and chains starting from altruists (up to max length, e.g., 4).
MIP Solver: Uses integer programming to maximize transplants by selecting disjoint cycles/chains.
Environment Interface: Provides a stateful environment for stepwise actions (select cycle/chain or terminate), tracking remaining graph and matched pairs. Rewards are exponential in matched pairs upon maximal termination.
Example output for a small instance (8 pairs, no altruists):

![KEP Env Figure](img/Figure_2.png)

Nodes table with IDs, types, blood types, cPRA.
Edges table listing source-target compatibilities.
Maximum matched pairs (e.g., via MIP).
Selected cycles/chains.
Visualization shows nodes colored by patient blood type (O: red, A: cyan, B: green, AB: yellow), with directed edges for compatibilities.

## Experiment: Demonstrating Collapse in Stochastic Environments (v1)

To illustrate the problem highlighted in the mathematical analysis, I've added a preliminary experiment inspired by the stochastic chain environment from Pan et al. (2023). This serves as a proof-of-concept to show how standard GFlowNets falter in stochastic settings, while the stochastic variant holds up. It's a simple chain where you start at state 0 and can either "stop" (terminate with reward at current state) or "continue" (move forward with probability p=0.5 or stay put with 0.5). The reward function is bimodal, with peaks around N/4 and 3N/4, making it a good test for capturing multiple modes without collapse.

In this env, the standard GFlowNet treats transitions as deterministic, ignoring the probabilistic branching. As N (chain length) grows, unmodeled stochasticity injects noise into the gradients, leading to higher variance, biased marginals, and eventual mode collapse— the model favors low-entropy paths, missing the true distribution. You see the KL divergence (measuring how far the sampled distribution is from the true posterior) spike for the standard version, while the stochastic one, which explicitly includes P(s' | s, a) in the balance, keeps the divergence low and stable.

This is just v1—a quick iteration to get the ball rolling and validate the critique. I'm building this iteratively, in the spirit of fail-fast-and-iterate: prototype, test, refine, push. It's how we move at speed in a world that's not slowing down—think Musk vs. the inertia of traditional research, where velocity can be intimidating but necessary for progress. No arrogance here, just the drive to expose flaws and fix them before they cost lives in applications like KEPs. For now, this Pan-inspired toy shows why stochasticity breaks the standard approach; I'm finalizing the full KEP simulation on my local machine (with Poisson arrivals, compatibility graphs, etc.) and will push updates in the coming hours or days. Expect polished proofs, more experiments, and iterative improvements as we die and retry to get it right.

Running the code below generate the plots. Here's the performance comparison (KL divergence vs. environment size):

![Performance Comparison: Standard vs Stochastic GFlowNet](img/Figure_1.png)  <!-- Replace with actual image link or embed -->

The env is highly stochastic

In the plot, the blue line (standard) climbs sharply as N increases, showing the collapse, while orange (stochastic) rises gently, staying closer to the truth.

    Code (PyTorch-based, runs locally):

## Future Directions

The next phase involves implementing a GFlowNet model to test on the KEP environment. The goal is to extend the approach by incorporating Stochastic GFlowNets with sub-trajectory balance, evaluating whether this leads to better convergence, reduced bias, and improved handling of stochastic dynamics in KEP simulations.

## References

- Pan et al. (2023). Stochastic Generative Flow Networks.
- St-Arnaud et al. (2025). A Learning-Based Framework for KEPs.
- Bengio et al. (2021). GFlowNet Foundations.

## License

This repository, including all text, mathematical derivations, conceptual simulations, and derived works, is licensed under the Creative Commons Attribution-NonCommercial 4.0 International License (CC BY-NC 4.0). You are free to share, copy, distribute, and adapt the material for non-commercial purposes, provided you give appropriate credit to the author, provide a link to the original repository (https://github.com/arthurmaffre/stochastic-kep-critique.git), and indicate if changes were made.

Citation Requirement: Any use of this work must include a citation to the author (please contact the repository owner for the preferred citation format) and the repository URL. For inquiries or to notify the author of use, contact the repository owner directly.

Commercial use is prohibited without explicit written permission from the author. Violations of this license will be pursued to the fullest extent permitted by law.


